{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类问题\n",
    "- 二分类\n",
    "    - 如果是onehotlabel是\\[10]还是\\[01]\n",
    "    - 或者逻辑斯蒂就是0还是1\n",
    "- 多类别分类\n",
    "    - 是二分类的推广\n",
    "- 多标签分类\n",
    "    - 比如一张图片可以同时属于多个类别\n",
    "    - 5个类,一个图的onehot可能是\\[11100]\n",
    "- 多任务分类\n",
    "    - 多标签的推广"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  分类概述\n",
    "input是一个图片\n",
    "\n",
    "output是一个高度抽象的符号\n",
    "\n",
    "也就是高维张量输出成了低位标量/向量\n",
    "\n",
    "## 常见数据集\n",
    "- Mnist: 0-9的十分类问题\n",
    "- Cifar: 彩图的多分类\n",
    "- ImageNet: 1000分类\n",
    "- Fashion_mnist: 衣服\n",
    "\n",
    "现在分类的数据集用来做理论算法的验证, 而精度不重要了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二分类\n",
    "一般不用one hot\n",
    "\n",
    "sigmoid:\n",
    "$$h_{\\theta}(\\vec{x}) = g(f(\\vec{x}))=g(\\vec{\\theta}^T \\cdot \\vec{x}))= \\frac{1}{1+e^{-\\vec{\\theta} ^T \\vec{x}}}$$\n",
    "Loss:\n",
    "$$J(\\theta)=-\\frac{1}{m} \\sum_{i=1}^{m}[y \\log (h_{\\theta}(x_{i}))+(1-y)\\log(1-h_{\\theta}(x_{i}))]$$\n",
    "\n",
    "Pytorch封装好了:\n",
    "\n",
    "```torch.nn.BCEWithLogitsLoss```\n",
    "\n",
    "## 多分类\n",
    "类和类必须平级\n",
    "\n",
    "不能包含\n",
    "\n",
    "甚至大类下面有子类, 不能使用\n",
    "\n",
    "类和类之间易于区分\n",
    "\n",
    "都是关于狗的,但是狗的细节有差别, 这样还没有很好的解决方法\n",
    "\n",
    "### 结构:\n",
    "\n",
    "图片-> n \\* (卷积 -> relu -> pooling) -> flatten -> 特征向量 -> FC -> SoftMax\n",
    "\n",
    "Loss: 交叉熵\n",
    "\n",
    "Pytorch封装好了: 两种方法:\n",
    "- ```torch.nn.CrossEntropyLoss```: 输入是softmax的结果, 输出就是loss\n",
    "\n",
    "- 先```torch.nn.logSoftmax```, 再```torch.nn.NLLloss```\n",
    "## 多标签分类:\n",
    "人类蛋白质分类\n",
    "\n",
    "一个图片可能属于多个类0001001110\n",
    "\n",
    "简化问题:\n",
    "\n",
    "多次二分类, 第一个是还是不是, 第二个是还是不是...\n",
    "\n",
    "Loss:\n",
    "\n",
    "```torch.nn.multiLabelSoftMarginLoss```\n",
    "\n",
    "```torch.nn.multiLabelMarginLoss```\n",
    "\n",
    "## 多任务分类\n",
    "\n",
    "之前的问题,都是每个类别都是\"是\"或者\"不是\"两种\n",
    "\n",
    "一张人脸图:\n",
    "- 性别:\n",
    "    - 男\n",
    "    - 女\n",
    "    - 其他\n",
    "- 帽子\n",
    "    - 有帽子\n",
    "    - 没帽子\n",
    "- 口罩\n",
    "    - 有口罩\n",
    "    - 没口罩\n",
    "    - 其他\n",
    "- 眼镜\n",
    "    - 太阳镜\n",
    "    - 近视镜\n",
    "    - 没有眼镜\n",
    "    - 其他\n",
    "\n",
    "分类的标签不能用onehot表示, 可能表示为1023\n",
    "\n",
    "而且数据不均衡会带来很大的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "# Linux:\n",
    "# /home/a/.cache/torch/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_trsfms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224,224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.4914,0.4822,0.4465],[0.247,0.243,0.261])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root=\".\",train=True, transform= my_trsfms,download=True)\n",
    "# 下载cifar10并解压放在此目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_dataset.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR10(root=\".\",train=False,transform=my_trsfms, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch借鉴了caffe，包括：\n",
    "- 数据结构:caffe叫blob, torch是tensor\n",
    "- 层功能定义: layer\n",
    "- 模型的结构: net\n",
    "- 最优化: caffe里叫solver, torch里是train和optim\n",
    "\n",
    "这是结构上一样，而对于数据流来说：torch:\n",
    "- 首先要读取图片，作为一个numpy形式的tensor\n",
    "- tensor进入内存，或者GPU显存\n",
    "- 不建议直接用tensor进行操作，要归一化，减去均值除以方差\n",
    "- 增广\n",
    "- 变成pytorch的tensor形式\n",
    "- 进入net（module）\n",
    "- 开始迭代，loss重新进入网络\n",
    "\n",
    "![20](20.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsize一般这些超参数要放在配置文件里\n",
    "# dataloader能帮助我们更快地载入数据集\n",
    "# 方便我们调整batchsize ,送到内存/显存里\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=16,shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset) # 测试集shuffle没有意义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_alexnet.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迁移学习：\n",
    "\n",
    "其他数据集训练模型\n",
    "\n",
    "在新的数据集上使用\n",
    "\n",
    "比如这里的alexNet，在ImageNet上训练，1000分类\n",
    "\n",
    "训练的时候我们把这个alexnet的前面参数, 也就是特征提取部分固定不变,拿过来, 对于最后的1000的全连接, 变成10分类\n",
    "\n",
    "固定的手段可以是lr=0\n",
    "\n",
    "这样变化, 会产生新的权重, 这些权重没有训练过, 重新初始化训练即可\n",
    "\n",
    "也就是使用了一个现成的backbone\n",
    "\n",
    "如果新数据集更大, 前面的参数需要变化, 可以选择小的lr,重新学习\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in my_alexnet.parameters():\n",
    "    i.requeires_grad = False\n",
    "\n",
    "# 让前面的参数不再训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_alexnet.classifier[6]=torch.nn.Linear(in_features=4096,out_features=10)\n",
    "# 这样做是错误的！\n",
    "\n",
    "in_f = my_alexnet.classifier[6].in_features\n",
    "my_alexnet.classifier[6]=torch.nn.Linear(in_f, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.001\n",
    "num_epoches = 10\n",
    "criteria=torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(my_alexnet.classifier[6].parameters(),lr=learn_rate,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('CPU')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "print(len(train_dataset[0]))\n",
    "print(train_dataset[0][0].shape)\n",
    "print(train_dataset[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "my_alexnet.to(device)\n",
    "my_alexnet.train()\n",
    "for epoch in range(num_epoches):\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    for idx,(img,label) in enumerate(train_dataloader):\n",
    "        images=img.to(device)\n",
    "        labels=label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = my_alexnet(images)\n",
    "        loss = criteria(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (idx+1)%100==0:\n",
    "            end = time.time()\n",
    "            print(f\"index: {idx}, current loss = {loss.item()}, time: {end-start}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval/test\n",
    "# 因为有标签,要验证\n",
    "my_alexnet.to(device)\n",
    "my_alexnet.eval() # my_alexnet.train(False) # 两者等价\n",
    "\n",
    "# eval和train参数更新方式不一样\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for image, label in test_dataloader:\n",
    "    \n",
    "    image_gpu = image.to(device)\n",
    "    label_gpu = label.to(device)\n",
    "\n",
    "    output = my_alexnet(image_gpu)\n",
    "    # print(output) # tensor: 2.6511, -0.8053, -1.3062,  0.1148,  0.1523,  0.9770, -2.3091, -0.5917, 0.0294, -0.1196\n",
    "    # 这样不行 我们需要最大值\n",
    "    correct += 1 if  torch.max(output, 1)[-1].to('cpu').to('cp=label else rrect)\n",
    "    total +=1\n",
    "    print(correct/total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多任务分类\n",
    "本身是个多标签分类的推广\n",
    "\n",
    "把每个类别对应一个任务\n",
    "\n",
    "那这个任务可能都不是分类问题 \n",
    "\n",
    "比如年龄 0-100, 回归问题\n",
    "\n",
    "这个叫多任务学习(MTL Multi Task Learning)\n",
    "\n",
    "变成多个任务会出现问题:\n",
    "- 数据不均衡\n",
    "    - 取数据的时候做一些纠正, 比如表情少, 头发多 , 可以复制重复的,增广, 多去少的, 少去多的\n",
    "    - GAN  对抗学习\n",
    " \n",
    "- 通常情况下, loss回传回去,训练出的网络, 更倾向于原来的数据\n",
    "\n",
    "- 类别a >> 大于类别b , 我们可对loss进行加权, 对于a的loss系数小, b的系数大, 这个叫加权CrossEntropyLoss\n",
    "\n",
    "### Weighted Cross Entropy Loss\n",
    "比如二分类\n",
    "$$Loss = -y \\log(P) - (1-y) \\log(P)$$\n",
    "$$ Weighted Loss = -\\alpha y \\log(P) - (1-\\alpha) (1-y) \\log(P)$$\n",
    "\n",
    "这样看似可以解决正负不均衡的问题,  但是 ,  \n",
    "\n",
    "类别\\训练|难|易|\n",
    "---|---|---|\n",
    "正a|0.6|0.99|\n",
    "负b|0.49|0.01|\n",
    "\n",
    "0.49意味着很难分辨\n",
    "\n",
    "意思是对于网络来说, 通过WCE能够辨别出是正样本还是负样本\n",
    "\n",
    "但是在难和易之间也是需要不平衡的\n",
    "\n",
    "因为如果很多样本是很困难的\n",
    "\n",
    "很少样本是容易的\n",
    "\n",
    "这种情况下没有辨别能力\n",
    "\n",
    "容易的多困难的少,这样不行\n",
    "\n",
    "困难的多容易的少,这是OK的\n",
    "\n",
    "\n",
    "这种难易的不均衡通过WCE无法解决\n",
    "\n",
    "正难>负难>正易>负易\n",
    "\n",
    "### Focal Cross Entropy Loss\n",
    "\n",
    "$$FCEL = -(1-P)^\\gamma \\log(P) - P^\\gamma \\log(1-P)$$\n",
    "\n",
    "当P(y=1)=0.9, \\gamma = 2\n",
    "\n",
    "可以对容易的样本做一个限制\n",
    "\n",
    "缺点: 过于关注难的样本.. 难的样本有可能是错的数据, \n",
    "\n",
    "解决: 难样本上产生过大梯度, 把它正则约束一下(gradient harmonize mechanism)\n",
    "### 两者结合\n",
    "\n",
    "$$ FocalLossWithWeight = -\\alpha (1-P)^\\gamma \\log(P) - (1-\\alpha)P^\\gamma \\log(1-P)$$\n",
    "\n",
    "### 多任务的学习策略\n",
    "\n",
    "一个Backbone 对应多个branches\n",
    "\n",
    "\n",
    "每个分支任务,或者叫功能会产生loss\n",
    "\n",
    "\n",
    "Loss最终相加, 考虑数量级 ,需要考虑权重\n",
    "![10](10.png)\n",
    "\n",
    "图中两种loss方式,一个最终相加\n",
    "\n",
    "一个分别计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Grained Classification\n",
    "\n",
    "细分类 \n",
    "\n",
    "比如 植物什么种类的,花朵什么花\n",
    "\n",
    "## Center Loss\n",
    "\n",
    "人脸领域用的也很多\n",
    "\n",
    "细分类其实是对图片本身做更多的标签\n",
    "\n",
    "比如花蕊, 花瓣的形状, 花的颜色\n",
    "\n",
    "又比如车品牌识别\n",
    "\n",
    "目前还比较困难, 不是很好\n",
    "\n",
    "\n",
    "### 分类的流程\n",
    "\n",
    "输入图片\n",
    "\n",
    "经过卷积等Backbone, 得到一个deeply learned features\n",
    "\n",
    "这个features比如说是向量vector\n",
    "\n",
    "vector经过我们的FC等操作\n",
    "\n",
    "得到预测标签\n",
    "\n",
    "利用LossFunction和真实标签做Loss\n",
    "\n",
    "![3.png](3.png)\n",
    "\n",
    "----------------\n",
    "\n",
    "我们希望那些deeply learned features如果相互之间分离性强\n",
    "\n",
    "也就是不同类别vector差别大,  同类别vector差别小\n",
    "\n",
    "-------------\n",
    "\n",
    "但是传统ML只能单纯的把两堆数据分开, 如图中xy二维坐标中红点和蓝点\n",
    "\n",
    "但是线附近的红点和蓝点, 差别并没有那么大\n",
    "\n",
    "蓝点凭什么跟红点靠的近呢? 那些直线附近的红点, 不应该更靠近边缘的红点吗?\n",
    "\n",
    "也就是缺少红色和红色的距离与红色与蓝色的对比\n",
    "\n",
    "\n",
    "缺少分得更开这样的细节\n",
    "\n",
    "### 意义\n",
    "\n",
    "出现了: 类内距离大于了类间距离\n",
    "Intra-class > Inter-class\n",
    "\n",
    "我们希望\n",
    "\n",
    "![4](4.png)\n",
    "\n",
    "而不是\n",
    "\n",
    "![5](5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Center Loss](https://ydwen.github.io/papers/WenECCV16.pdf) \n",
    "\n",
    "Mnist 经过Backbone得到二位向量, 直接画这个二维向量:\n",
    "![5](6.png)\n",
    "\n",
    "\n",
    "中心部分大家相似, 周围大家相差很多\n",
    "\n",
    "embedded表现\n",
    "\n",
    "比如有些图片7长的像1\n",
    "\n",
    "\n",
    "用传统ML在中心部分很难区分\n",
    "\n",
    "这个是数据本身带来的\n",
    "\n",
    "我们希望 Deeply learned features 离散型更强, 就引入center loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center Loss\n",
    "loss值包括两项:\n",
    "- 分类结果对不对 \n",
    "- 每个类中所有点到该类的中心点距离之和\n",
    "\n",
    "这样:\n",
    "- 不仅分类正确\n",
    "- 而且中间的特征向量的聚集程度也提升了\n",
    "也当作loss值一部分\n",
    "\n",
    "### 具体 过程:\n",
    "\n",
    "所有点到中心点距离之和的一半\n",
    "\n",
    "$$L_{C} =\\frac{1}{2}\\sum_{i=1}^{m} ||\\vec{x_{i}}-\\vec{c_{y_{i}}}||_{2}^{2}$$\n",
    "c_yi就是该类中心点的坐标\n",
    "\n",
    "$$\\vec{c_{y_{i}}} =\\frac{1}{m} \\sum_{x_{i}\\in y_{i}}^{m}x_{i}$$\n",
    "对于第t次到t+1次:\n",
    "\n",
    "总loss\n",
    "$$ L = L_{S} + \\lambda L_{C}$$\n",
    "\n",
    "对每个样本i, 反传梯度\n",
    "\n",
    "$$\\frac{\\partial L^{t}}{\\partial x_{i}^{t}}=\\frac{\\partial L_{S}^{t}}{\\partial x_{i}^{t}} +\\lambda \\frac{\\partial L_{C}^{t}}{\\partial x_{i}^{t}}$$\n",
    "\n",
    "更新center loss层的参数W, \\mu为学习率:\n",
    "\n",
    "$$W^{t+1} = W^{t} - \\mu^{t}$$\n",
    "\n",
    "$$\\frac{\\partial L^{t}}{\\partial W^{t}} = W^{t}-\\mu^{t}\\cdot\\frac{\\partial L_{c}^{t}}{\\partial x_{i}^{t}}$$\n",
    " \n",
    "对于每个参数j, j是类别 ,更新cj\n",
    "\n",
    "\n",
    "$$\\vec{c_{j}}^{t+1} = \\vec{c_{j}}^{t} - \\alpha \\Delta \\vec{c_{j}} $$\n",
    "\n",
    "\\alpha 一般取0.8 ~ 0.9, 用于控制波动情况\n",
    "\n",
    "C_yi不是固定的， 是所有点的中心:\n",
    "\n",
    "$$\\Delta \\vec{c_{j}} =\\frac{ \\sum_{i=1}^{m} \\delta(y_{i} = j)\\cdot( \\vec{c_{j}}-\\vec{x_{i}})  }{1+\\sum_{i=1}^{m} \\delta(y_{i}=j)}$$\n",
    "\n",
    "其中\n",
    "\n",
    "$$\\delta(True) =1$$\n",
    "\n",
    "$$ \\delta(False)=0$$\n",
    "\n",
    "更新\\theta_{C}\n",
    "\n",
    "$$\\theta_{C}^{t+1} =\\theta_{C}^{t} -\\mu^{t} \\sum_{i=1}^{m}\\frac{\\partial L^{t}}{\\partial x_{i}^{t}}\\cdot\\frac{\\partial x_{i}^{t}}{\\partial \\theta_{C}^{t}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而Center Loss在Mnist作用好, 在Cifar10上差\n",
    "\n",
    "因为Cifar同一类中样本数据距离大, 不适用\n",
    "\n",
    "人脸, 比如人脸属于哪个类, 非常适用CenterLoss\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Triplet Loss\n",
    "- Contrastive Loss\n",
    "\n",
    "也非常适用于人脸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 残差注意力网络\n",
    "\n",
    "注意力机制:\n",
    "\n",
    "关注点集中在可区分的特征上\n",
    "\n",
    "比如热气球的图片,注意力不应该放在天空或者高楼上\n",
    "\n",
    "网络的关键就是一个沙漏(Bottom-up)结构加上一个sigmoid, 得到一个0,1之间的权重值\n",
    "\n",
    "\n",
    "然后权重乘以原图再+原图\n",
    "\n",
    "![7](7.png)\n",
    "经过一系列变换, 热气球确实只关注了气球本身\n",
    "\n",
    "但是过于关注尖端部分,因此陀螺也很容易识别为气球"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证集精度高于训练集的问题\n",
    "\n",
    "![8](8.png)\n",
    "\n",
    "- 训练集数据作了增广, 预处理, 这些增广很有可能做坏了, 分布变差了, 导致loss降得慢\n",
    "    - 比如一张图片增广后, 在验证集上很少找到对应的, 这张就很难训练\n",
    "- 正则化模型, 比如DropOut, 训练丢弃了很多, 验证又全都要. 正则化过多会使模型有差异\n",
    "\n",
    "- 验证的时候, 是在每个epoch结束时验证, 训练loss可以在每个bactch得到. 也就是说, 验证晚于训练, 所以显然会loss小"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdeeplearningconda4eb25749ed314365ad1de507c177859b",
   "display_name": "Python 3.7.6 64-bit ('deeplearning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}