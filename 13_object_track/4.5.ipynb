{"cells":[{"cell_type":"markdown","metadata":{},"source":["计算机视觉三大任务\n","- 目标检测\n","- 目标分割\n","- 目标跟踪\n"]},{"cell_type":"markdown","metadata":{},"source":["# 目标跟踪 Object Tracking"]},{"cell_type":"markdown","metadata":{},"source":["# 历史发展\n","\n","目标跟踪是一个很大的领域\n","\n","在deeplearning没有出现的时候就有跟踪了\n","\n","2010-2012 TLD track learning detection\n","\n","2012 corlatin filter相关滤波\n","\n","2012之后 Siamese基于孪生, 基于CNN\n","\n","甚至认为跟踪就是检测的复合任务"]},{"cell_type":"markdown","metadata":{},"source":["# 跟踪简述\n","## 什么是跟踪\n","- 很多时候应该叫做 visual tracking\n","    - 比如颜色, 没有物体出现的区域\n","- 还有 target tracking \n","    - 比如敌方飞机, 这是在object出现之前就已经知道它是什么了\n","- 甚至还有 把tracking换成tracing(轨迹)\n","- 第一帧如果没有任何物体, 从某一时刻开始出现我们感兴趣的物体, 这时候也需要recognition\n","\n","\n","强调在很多物体的表现很好, 而不是固定种类\n","\n","比如ufo从来没见过, oneshot learning\n","\n","难点: 视角, 姿态,运动,  重叠, 遮挡, 多个相似, 抖动, 亮度, 变色, 突然消失, 要鲁棒性好\n","\n","实时性(评价指标: mIOU)\n","\n","## 简介视频\n","\n","re3: Real-Time Recurrent Regression Networks for Visual Tracking of Generic Objects\n","\n","[re3](https://gitlab.cs.washington.edu/xkcd/re3-tensorflow)\n","\n","\n","## 输入输出\n","\n","输入是图片序列sequence, 是有顺序的; 而不是集合set, 不是一堆图片\n","\n","通常, 输入还应该有第一帧目标的位置\n","\n","具体输入形式,有9种\n","\n","比如中心点, 轮廓上12个点, bbox, 斜的bbox, 全部轮廓, 内部填充物mask, 骨架, 等等\n","\n","输出接下来每一帧目标可能的位置\n","\n","## 应用场景\n","\n","- 工业机器人\n","- 监控\n","- 交通\n","- VR(包括传感器)\n","- 需要其他信号,比如gps, 声纳\n","\n","## 分类&分支方向\n","\n","按目标多少: 多目标, 单目标(这两个领域完全不同)\n","\n","第一帧是否给定(企业级往往没有)\n","\n","Model-Free\n","\n","![1](1.PNG)\n","\n","- Environment:\n","    - 如果是真实场景, 就需要我们人工拍摄\n","    - 约束环境: 虚拟几何体, 利用摄影知识,完成环境变化\n","- 摄像头Camera\n","    - 多个视角\n","    - 其他摄像头,红外,声纳\n","- 失效性\n","    - 长时跟踪\n","    - 短时跟踪(目标消失)\n","- 物体种类与数量\n","- 数据集\n","- 指标"]},{"cell_type":"markdown","metadata":{},"source":["## 挑战\n","1. Motion blur 运动模糊 ,边界不清楚\n","2. Occlusion 遮挡(框如何变化)\n","3. Deformation 变形,如跳舞的姿态\n","4. Scale variation 尺度, 大小, 车跑过来\n","5. Move too fast 运动太快可能不连续\n","6. Exposure change 曝光点变化\n","\n","最重要的: 缺少训练样本\n","\n","> 肯定要增广!!"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"markdown","metadata":{},"source":["# 分类\n","\n","多目标\n","\n","单目标\n","\n","这两个完全不同的方向, 没办法用一个方案同时解决两个\n","\n","\n","第一帧是否给定: 一般给定\n","\n","在企业业务中可能没有\n"]},{"cell_type":"markdown","metadata":{},"source":["# 主要的挑战\n","框的大小变化\n","\n","本身姿态变形(跳舞,弯腰)\n","\n","尺度变化屏幕占比(车远近,)\n","\n","\n","最大的困难:缺少训练样本\n","\n","需要Augmentation\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# 问题的简化\n","\n","## 简化成detection\n","每一帧都提出来:\n","- 可能闪烁 可能有些帧没有\n","- 损失信息.导致输出不准确,不能考虑前后的连贯性\n","\n","弥补:\n","- 比如前后帧差别太大, 剔除\n","- 比如前后帧消失,插补\n","\n","## 背景固定\n","\n","背景的像素固定(比如监控录像, 只有光照略微变化)\n","\n","关键是找到背景如何变化的, 第二帧减去第一帧:\n","\n","### 线性变换法\n","\n","- 具体来说, 应该找到两张图片的关键点\n","- 发现第一帧很多关键点经过单应性矩阵变换到了第二帧\n","- 此时应该 2 - H * 1\n","\n","### 帧插法\n","\n","单纯的第二帧减第一帧\n","\n","做阈值筛出变化的东西, 就是运动的物体\n","\n","### 光流法\n","\n","背景可能存在一种不为人知的变化\n","\n","把背景的每个像素点当作光点, 每时每刻发生变化\n","\n","预测光流场在下一个时刻怎么变化\n","\n","给函数带入t值, 得到背景, 每帧减去背景即可\n","\n","\\(个人想法: 拉格朗日法和欧拉法\\)\n","\n","### 背景削弱\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### 帧插法 演示"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","import os\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["root_path = os.curdir\n","video_path = os.path.join(root_path, \"long.mp4\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","# import matplotlib\n","# matplotlib.use('Qt5Agg')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cap = cv2.VideoCapture(video_path)\n","frame_num = 0\n","# plt.ion()\n","while cap.isOpened():\n","    ret_status, frame = cap.read()\n","    frame_num+=1\n","    if ret_status:\n","        temp_frame = frame\n","        if frame_num ==1:\n","            prev_frame = cv2.cvtColor(temp_frame, cv2.COLOR_BGR2GRAY)\n","        if frame_num>2:\n","            curr_frame = cv2.cvtColor(temp_frame, cv2.COLOR_BGR2GRAY)\n","            curr_frame = cv2.absdiff(curr_frame,prev_frame)\n","\n","\n","            # 阈值变化处理, 二池化操作, 放大\n","            # 对于40分界, 超过40就绝对亮\n","            # 这里要把一些背景中变化的东西剔除调\n","            _, threshold_frame = cv2.threshold(curr_frame,40,255,cv2.THRESH_BINARY)\n","\n","            # 降噪\n","            gaussian_frame = cv2.GaussianBlur(threshold_frame, (3,3),0)\n","\n","            img, contours,hia = cv2.findContours(gaussian_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","            # print(contours)\n","            for c in contours:\n","                if cv2.contourArea(c)>=150:\n","                    (x,y,w,h) = cv2.boundingRect(c)\n","                    cv2.rectangle(frame,(x,y),(w+x,y+h),(255,255,0),2)\n","            # plt.subplot(121)\n","            # plt.imshow(curr_frame)\n","            # plt.subplot(122)\n","            # plt.imshow(threshold_frame)\n","            # plt.pause(0.033)\n","            cv2.imshow('ORIGIN',cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","            cv2.imshow('ABSDIFF', curr_frame)\n","            cv2.imshow('BINARY', threshold_frame)\n","            cv2.imshow('GAUSSIAN', gaussian_frame)\n","\n","            if cv2.waitKey(33) & 0xFF==ord('q'):\n","                break\n","        prev_frame = cv2.cvtColor(temp_frame, cv2.COLOR_BGR2GRAY)\n","cap.release()   \n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# 跟踪器\n","\n","跟踪器有上百种, 留下来的也就几种\n","\n","实时性很关键(绝大多数情况下, 都是在线跟踪, 只知道当前帧和历史帧)\n","\n","![2](2.PNG)\n","\n","主要分4类\n","- Dataset\n","    - VOT竞赛\n","    - OTB object tracking benchmark\n","    - 其他\n","- Others\n","    - 静态背景\n","    - RL\n","    - ...\n","- 相关滤波\n","    - KCF\n","    - CNN\n","- CNN\n","    - 基于检测\n","    - 孪生网络\n","\n","\n","## 相关滤波\n","\n","## 使用了核方法的相关滤波\n","快\n","\n","离散傅里叶, 对于原始样本增强和采样的速度大大提高\n","\n","循环矩阵最小化\n","\n","用了HOG特征\n","\n","## 卡尔玛滤波 Kalman filter\n","\n","> 广泛用在控制和航天\n","\n","### CCOT\n","\n","### MD NET\n","\n","1:56"]},{"cell_type":"markdown","metadata":{},"source":["## Siam R-CNN 2019 基于检测\n","\n","[论文地址](https://arxiv.org/abs/1911.12836v1)\n","\n","![3](3.PNG)\n","\n","直接使用检测的backbone\n","\n","孪生的意义:\n","\n","    第一帧, 当前帧都使用了deep feature extractor\n","\n","    而且经过的时候权值不变(shared weight)\n","\n","    两个输入进入, 两个输出\n","\n","1. 第一帧经过backbone生成特征图\n","2. 把第一帧的bbox信息, 投影到特征图上, 并使用ROI align,得到固定大小的一个特征图\n","3. 当前帧进入backbone生成特征图, 特征图进入region proposal network, 得到区域建议, 也使用ROI align,得到多个固定大小的特征图\n","4. 将3的结果分别和2的结果concat, 先re-detection,也就是再回归, 分数越高, 说明越可能是第一帧出现的\n","5. 对4的结果进行筛查,考虑前几帧, 大小夸张的去掉, 离得远的去掉等等\n","6. 用5的结果, 使用4中同样的re-detection网络, 再检测, 得到更加真实的框\n","7. 对6的结果进行一些动态的预估, 并且插值放大, 放到原图上\n","8. (可选)把7的结果进行分割, 画出物体的边缘"]},{"cell_type":"markdown","metadata":{},"source":["## 相关滤波 Correlation Filters\n","\n","### 什么是\"相关\"\n","相关, 类似于协方差\n","\n","比如大图中有个小人, 一张小图就是那个小人\n","\n","拿小图和大图卷积, 得到score map\n","\n","是响应分数, 也是相关操作\n","\n","### 真实情况\n","\n","但是这种相关操作很慢, 用点乘更好\n","\n","傅里叶变换可以把卷积变成乘法\n","\n","小图其实是第一帧出现的目标\n","\n","大图小图分别做傅里叶变换, 然后点乘\n","\n","点乘结果逆傅里叶变换, 得到结果\n","\n","相当于在时域频域做了变换\n","\n","### MOSSE 2010\n","\n","minimum output sum of square error\n"," \n","最小方差输出的滤波器\n","\n","![4](4.PNG)\n","\n","Gi是响应图\n","\n","G = f 卷积 h\n","\n","f 是大图, h 是小图\n","\n","目的: 找到一个合适的h, 使得每一帧, 卷积的时候, g在目标区域达到最大, 接近gt\n","\n","也就使下式最小:\n","$$ \\sum_{i=1}^{N}|f_{i} * h -g_{gt_{i}}|^2$$\n","\n","将f,g,h傅里叶变换:\n","$$ \\underset{H}{argmin}\\sum_{i=1}^{N}|F_{i} \\odot H -G_{i}|^2$$\n","\n","求导可解共轭\n","\n","$$ H^{*} = \\frac{\\sum_{i}^{N}G_{i}\\odot F_{i}^{*}}{\\sum_{i}^{N}F_{i}\\odot F_{i}^{*}}$$\n","\n","线上更新, 不可能拿到所有帧\n","\n","只能用之前的:\n","\n","$$ H_{i}^{*} = \\eta\\frac{G_{i}\\odot F_{i}^{*}}{F_{i}\\odot F_{i}^{*}}+(1-\\eta ) H_{i-1}^{*}$$\n","\n","实际上还对每一帧作了增广\n"]},{"cell_type":"markdown","metadata":{},"source":["### 核相关滤波器 Kernelized Correlation Filters\n","\n","#### 循环矩阵: \n","\n","用来增广样本\n","\n","比如当样本是一维的:\n","\n","![5](5.PNG)\n","\n","三维图片:\n","\n","![6](6.PNG)\n","\n","#### 循环矩阵的性质:\n","\n","可以对角化\n","\n","![7](7.PNG)\n","\n","#### KCF算法:\n","\n","第一帧,训练一个滤波器, 使得第一帧在目标位置响应最强\n","\n","第二帧同样,  用循环矩阵增广, 训练一个滤波器, 使得之前所有找到的更准确"]},{"cell_type":"markdown","metadata":{},"source":["## SiamFC 2015\n","\n","[论文](https://arxiv.org/abs/1606.09549)\n","\n","![8](8.PNG)\n","\n","\n","目标和当前帧同时送入backbone\n","\n","backbone不训练\n","\n","两者的输出做相关\n","\n","得到响应图"]},{"cell_type":"markdown","metadata":{},"source":["## SiamRPN\n","\n","[论文](https://arxiv.org/abs/1606.09549)\n","\n","![9](9.PNG)\n","\n","模板帧和检测帧都进入CNN\n","\n","然后结果一个分支做分类(是还是不是)\n","\n","一个分支做回归"]},{"cell_type":"markdown","metadata":{},"source":["## SiamMask 2019竞赛亚军\n","\n","[视频](https://www.bilibili.com/video/BV1Kt411u7CT)\n","\n","[论文](http://www.robots.ox.ac.uk/%7Eqwang/SiamMask/)\n","\n","[开源](https://github.com/foolwood)\n","\n","![10](10.PNG)\n","\n","![11](11.PNG)\n","\n","作者认为: 跟踪精度上限, 不是由框决定, 由分割决定\n","\n","单纯跟踪框精度不行的\n","\n","当前帧和目标值也是进入相同的backbone, 得到特征图, 做相关操作\n","\n","每一个长条都是响应分数\n","\n","256通道可以做成63x63,做成mask\n","\n","生成mask的过程类似于unet, 多尺度融合\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## SiamRPN, SiamMask, KalmanFilter还在用"]},{"cell_type":"markdown","metadata":{},"source":["## Kalman filter\n","\n","控制算法\n","\n","转变思维: 估算方法, 使得我们估算的东西方差最小\n","\n","适用于: 线性系统+ 高斯噪声 (非高斯 粒子滤波)\n","\n","\n","场景: 小车在走, 我们在路边不动, 每个时刻都观测它\n","\n","t时刻, 观测值, 距离zt, 这是个标量, 小车的状态xt=\\[position_t, vt\\]\n","\n","zt未必等于position_t, 有误差\n","\n","zt是均值, R是协方差矩阵(或者标量方差)\n","\n","根据牛顿第二定律，我们其实可以知道上一时刻\n","\n","$$p_{t}=p_{t-1}+\\Delta t \\cdot v_{t} + \\frac{1}{2}\\Delta t^2 \\cdot a_{t}$$\n","\n","$$v_{t} = v_{t-1} + \\Delta t \\cdot a_{t}$$\n","\n","状态转移方程：\n","\n","\n","$$x_{t}=\\begin{bmatrix}1&\\Delta t \\\\0&1\\end{bmatrix}x_{t-1}+\\begin{bmatrix}\\frac{1}{2}\\Delta t^2 \\\\ \\Delta t\\end{bmatrix}a_{t}$$\n","\n","$$x_{t}=F_{t}\\cdot x_{t-1} + B_{t}\\cdot u_{t}$$\n","\n","F是状态转移矩阵， B是控制矩阵\n","\n","协方差：\n","$$P_{t}=F_{t}P_{t-1}F_{t}^{T}$$\n","\n","以上两个都是预测值，预测不准\n","\n","应该有：\n","\n","$$P_{t}=F_{t}P_{t-1}F_{t}^{T}+Q$$\n","\n","观测方程：\n","\n","$$z_{t} = H\\cdot x_{t} +V$$\n","\n","V是误差， 没有速度信息所以H=\\[1, 0\\]\n","\n","状态更新：\n","\n","$$\\hat{x_{t}}^{kalman}=x_{t}+K_{t}(z_{t}-H\\cdot x_{t})$$\n","\n","K是卡尔曼增益kalman gain，不仅转换量纲，而且还能表达权重，这是核心\n","\n","方差最小可求卡尔曼增益\n","\n","$$K_{t}=P_{t}H^{T}(HP_{t}H^{T} + R) ^{-1}$$"]},{"cell_type":"markdown","metadata":{},"source":["其实标量情况下，\n","$$K=\\frac{P}{P+R}$$\n","\n","k=1，说明更相信观测值，k=0，更相信推测值"]},{"cell_type":"markdown","metadata":{},"source":["$$P_{t}=(1-K_{t}H)P_{t}$$\n","\n","方差是变大的"]},{"cell_type":"markdown","metadata":{},"source":["其实卡尔曼滤波就是：\n","\n","准确地推断出下一个时刻小车的位置\n","\n","但是我们既不能相信我们的推断，也不能相信我们的观测\n","\n","要基于推测和观测，之间，求一个加权值\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 模拟数据\n","\n","t = np.linspace(1,100,100)\n","\n","position_gt = 0.5 *t **2\n","position_observed = position_gt +np.random.normal(0,500,size=t.shape[0])\n","plt.plot(t,position_gt,label='truth we never know')\n","plt.plot(t,position_observed,label='observed position')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 用上一个状态推测下一个\n","\n","# 第一次估计就用第一个观测值\n","Q=50\n","predicts_kalman = [position_observed[0]]\n","\n","position_predict = position_observed[0]\n","var_observed = 1000\n","var_predict = 100\n","for i in range(1,t.shape[0]):\n","    dv = position_gt[i] - position_gt[i-1] + np.random.normal(0,50)\n","    position_predict += dv\n","    var_predict += Q\n","\n","    # kalman filter\n","    position_predict = position_predict* var_observed/(var_observed+var_predict) +position_observed[i] *var_predict / (var_observed+var_predict)\n","\n","    var_predict = var_predict * var_observed/(var_predict+var_observed)**2\n","    predicts_kalman.append(position_predict)\n","\n","plt.scatter(t,predicts_kalman, label='kalman')\n","\n","plt.plot(t,position_gt,label='truth we never know')\n","plt.plot(t,position_observed,label='observed position')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["给定一个状态，如何变到下一个状态\n","\n","包括状态，状态的协方差矩阵\n","\n","注意这里是推断的协方差矩阵，而不是真实的，真实的永远只有一个，是未知的"]},{"cell_type":"markdown","metadata":{},"source":["## 用opencv实现track"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","import os\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["root = os.curdir"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_tracker_by_name(tracker_name):\n","    tracker_list = ['BOOSTING', 'MIL', 'KCF','TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n","    if tracker_name in tracker_list:\n","        return eval(f'cv2.Tracker{tracker_name}_create()')\n","    else:\n","        print(f'ERROR: tracker \"{tracker_name}\" not found in {tracker_list}')\n","        return None\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["video_path = os.path.join(root,'short.mp4')\n","cap = cv2.VideoCapture(video_path)\n","status, frame = cap.read()\n","if status!= True:\n","    print('ERROR: failed to read video')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bbox_list = []\n","color_list = []\n","while True:\n","    bbox=cv2.selectROI('MultiTracker', frame)\n","    print(type(bbox))\n","    bbox_list.append(bbox)\n","    color_list.append((random.randint(0,255),random.randint(0,255),random.randint(0,255)))\n","    print(bbox_list,color_list)\n","    print(\"Press q to quit selecting boxes and start tracking\")\n","    print(\"Press any other key to select next object\")\n","    if cv2.waitKey(0) & 0xFF ==ord('q'):\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tracker_str = 'KCF'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["multi_tracker = cv2.MultiTracker_create()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for bbox in bbox_list:\n","    multi_tracker.add(create_tracker_by_name(tracker_str),frame,bbox)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["while cap.isOpened():\n","    status, frame = cap.read()\n","    \n","    status, new_box_list = multi_tracker.update(frame)\n","\n","    for index, new_box in enumerate(new_box_list):\n","        p1 = (int(new_box[0]), int(new_box[1]))\n","        p2 = (int(new_box[0] + new_box[2]),int(new_box[1]+new_box[3]))\n","        cv2.rectangle(frame,p1,p2,[255,0,255],1,1)\n","    cv2.imshow('MultiTracker', frame)\n","\n","    if cv2.waitKey(2) & 0xFF ==27:#ESC\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.6-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python37664bitdeeplearningconda4eb25749ed314365ad1de507c177859b","display_name":"Python 3.7.6 64-bit ('deeplearning': conda)"}},"nbformat":4,"nbformat_minor":2}