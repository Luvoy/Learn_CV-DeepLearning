{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Stage Image Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Faster RCNN还是有些慢\n",
    ">\n",
    "> 为什么要做两步？先预测感兴趣的区域再分类？能不能一步到位？\n",
    ">\n",
    "> 直接判定anchor属于哪个类别不可以吗？\n",
    ">\n",
    "\n",
    "生成anchor判定类别：SSD的思路\n",
    "\n",
    "YOLO 速度精度高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v1 (2015)\n",
    "\n",
    "[论文地址](https://arxiv.org/pdf/1506.02640.pdf)\n",
    "\n",
    "![1](1.PNG)\n",
    "\n",
    "## 流程\n",
    "\n",
    "1. 先在原图（448x448）划分7x7的网格，一个格子叫一个cell\n",
    "2. 当且仅当物体中心落在一个cell上，那么这个cell负责预测这个物体。\n",
    "    - 两个物体中心落在一个cell上，只会负责先来的（存在漏检情况）\n",
    "    - 网格划分可以更细\n",
    "\n",
    "输入： 448x448x3\n",
    "\n",
    "输出： 7x7x（2x5+20）\n",
    "\n",
    "每个cell预测2个bonding_box，这个bonding_box是回归出来的，是网络生成的\n",
    "\n",
    "bonding_box有5个值: center_x, center_y, w, h, confidence\n",
    "\n",
    "confidence(置信程度): P(是否包含感兴趣的物体) x IoU(gt和bbox的）\n",
    "\n",
    "中心cell的P为1，非中心cell的P为0\n",
    "\n",
    "20是分类的类别数。用confidence高的那个bbox\n",
    "\n",
    "## Loss\n",
    "\n",
    "![2](2.PNG)\n",
    "\n",
    "设s是网格每条边数, 那么网格数就是s的平方\n",
    "\n",
    "设B是bbox数量, 比如前文为2\n",
    "\n",
    "$$\\mathbf{1}_{i,j}^{obj}$$\n",
    "\n",
    "1obji表示对象是否出现在单元格i中，1obij表示单元格i中的第j个边界框预测值负责该预测\n",
    "\n",
    "\n",
    "### bbox位置 Loss\n",
    "\n",
    "$$ \\lambda_{coord}\\sum_{i=0}^{s^2}\\sum_{j=0}^{B}\\mathbf{1}_{i,j}^{obj}[(x_{i}-\\hat{x_{i}})^{2}+(y_{i}-\\hat{y_{i}})^{2}]$$\n",
    "\n",
    "\n",
    "\\lambda_{coord} 一般取5,因为30个通道里位置的太少了\n",
    "\n",
    "### bbox宽高 Loss\n",
    "\n",
    "$$ \\lambda_{coord}\\sum_{i=0}^{s^2}\\sum_{j=0}^{B}\\mathbf{1}_{i,j}^{obj}[(\\sqrt{w_{i}}-\\sqrt{\\hat{w_{i}}})^{2}+(\\sqrt{h_{i}}-\\sqrt{\\hat{h_{i}}})^{2}]$$\n",
    "\n",
    "用根号仍然显得很随意, 不能对大物体充分抑制, 对数更好\n",
    "### 置信度 Loss\n",
    "设C为置信度, C= P x iou\n",
    " \n",
    "$$\\sum_{i=0}^{s^2}\\sum_{j=0}^{B}\\mathbf{1}_{i,j}^{obj}(C_{i}-\\hat{C_{i}})^2 + \\lambda_{no\\_obj}\\sum_{i=0}^{s^2}\\sum_{j=0}^{B}\\mathbf{1}_{i,j}^{no\\_obj}(C_{i}-\\hat{C_{i}})^2$$\n",
    "\n",
    "显然, 后面那个hat ci为0, 因为它不负责预测\n",
    "\n",
    "\\lambda_{no\\_obj}取0.5,因为不负责预测的太多了\n",
    "\n",
    "### 类别 Loss\n",
    "$$\\sum_{i=0}^{s^2}\\mathbf{1}_{i}^{obj}\\sum_{c\\in classes}(p_i(c)-\\hat{p_i}(c))^2$$\n",
    "\n",
    "### 总Loss将这些Loss加起来即可\n",
    "\n",
    "## 优点\n",
    "\n",
    "1. 快\n",
    "2. FP很低\n",
    "3. 宁可漏检也不会误检\n",
    "\n",
    "## 缺点\n",
    "\n",
    "1. 一张图7x7的网格, 最多能预测多少个bbox? \n",
    "    - 7x7x2个bbox, 但是只能7x7x1个物体\n",
    "2. 1个cell只能预测一个object\n",
    "    - 对于小物体不太好\n",
    "    - 对于拥挤的不太好\n",
    "3. 使用了全连接, 最后变成7x7x30, 这里完全可以用卷积代替\n",
    "4. 取根号并不最好\n",
    "5. 没有BN\n",
    "6. 训练集里没有的长宽比, 预测不好\n",
    "\n",
    "这也导致yolo v1的precision很低, recall 不高, \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v2 (2016)\n",
    "\n",
    "[论文地址](https://arxiv.org/pdf/1612.08242.pdf)\n",
    "## 从V1的改进\n",
    "\n",
    "1. 加入BN\n",
    "\n",
    "2. 高分辨率分类\n",
    "    - 先用224x224训练\n",
    "    - 用448x448进行finetune\n",
    "    - 给任务的训练集做finetune\n",
    "    - 7x7变成13x13\n",
    "\n",
    "3. **用anchor**\n",
    "\n",
    "作者认为faster-rcnn中人为指定9种anchor不合适\n",
    "\n",
    "这里对训练集的gt数据用k-means聚类得到Anchor\n",
    "\n",
    "这里计算的是框和框之间的距离\n",
    "\n",
    "每个cell有5个anchor, 总共13x13x5=845个\n",
    "\n",
    "\n",
    "4. 细粒度特征融合 Fine-Grained features\n",
    "\n",
    "> CNN提取语义信息(高级特征), 会同时损失像素信息(低级特征)\n",
    ">\n",
    "> CNN也同时损失了一些位置信息\n",
    "\n",
    "我们想把低级特征和高级特征融合在一起\n",
    "\n",
    "可以做一个分支, 把低级和高级的直接相加\n",
    "\n",
    "但是有尺寸问题\n",
    "\n",
    "作者提出一个新的层 reorg\n",
    "\n",
    "把一个大图变成多个小图, 再和小图相加\n",
    "\n",
    "这样能更好的用低级特征\n",
    "\n",
    "5. 多尺度训练 Multi-Scale Training\n",
    "\n",
    "多个不同分辨率进行训练, 去除了FC层, 就可以接受任意尺寸输入了\n",
    "\n",
    "## anchor计算\n",
    "\n",
    " \n",
    "5个anchor, 每个anchor有w和h, 共10个值\n",
    "\n",
    "WH为整个图片的宽高\n",
    "\n",
    "以a1为例:\n",
    "\n",
    "$$a_{1_{w}}=\\frac{a_{w_{ori}}}{W} \\times 13$$\n",
    "$$a_{1_{h}}=\\frac{a_{h_{ori}}}{H} \\times 13$$\n",
    "\n",
    "原始有真正的bbox,(gt), 4个值\n",
    "$$[x_{o},y_{o},w_{o},h_{o}]$$\n",
    "归一化:\n",
    "$$[x_{r},y_{r},w_{r},h_{r}]= [x_{o}/W,y_{o}/H,w_{o}/W,h_{o}/H]$$\n",
    "归一化之后, 他们都介于0,1之间\n",
    "\n",
    "乘以13:\n",
    "$$[x,y,w,h]=[13x_{o}/W,13y_{o},13w_{o}/W,13h_{o}/H]$$\n",
    "\n",
    "当前格化, 也就是减去索引, 也就是减去整数部分:\n",
    "$$[x_{f},y_{f},w_{f},h_{f}] = [x-\\left \\lfloor  {x}\\right \\rfloor,y-\\left \\lfloor {y} \\right \\rfloor,\\log{\\frac{w}{anchors[0]}},\\log{\\frac{h}{anchors[1]}}]$$\n",
    "\n",
    "此时, x_f,y_f坐标就是相对于某个格子左上角的相对坐标,\n",
    "\n",
    "而不是相对整张图左上角的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v3 (2018)\n",
    "[原文地址](https://pjreddie.com/media/files/papers/YOLOv3.pdf)\n",
    "\n",
    "借鉴了ResNet\n",
    "\n",
    "参考了FPN, 特征金字塔网络\n",
    "\n",
    "多尺度特征网络\n",
    "\n",
    "3个尺度的cell划分:\n",
    "- 13x13\n",
    "- 26x26\n",
    "- 52x52\n",
    "\n",
    "每个cell有3个anchor, 总9个\n",
    "\n",
    "\n",
    "分类是80类, 多标签, \n",
    "\n",
    "多个二分类 \n",
    "\n",
    "用的logistic\n",
    "\n",
    "3个尺度每个都会输出\n",
    "\n",
    "之前是一个cell预测一个, 输出量:2x(4+1)+20\n",
    "\n",
    "现在是一个anchor预测一个, 输出量:\n",
    "\n",
    "13x13x3x(4+1+80) + 26x26x3x(4+1+80) + 52x52x3x(4+1+80)\n",
    "\n",
    "注意把80放在括号里了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPN Feature Pyramid Network\n",
    "\n",
    "[论文地址](https://arxiv.org/pdf/1612.03144.pdf)\n",
    "### 简述:\n",
    "\n",
    "既要参考高级的语义特征,又想参考低级的像素特征\n",
    "\n",
    "图片卷积不断变小, 变小的可以拿出来, 放大(插值/转置卷积), 与原来的图elementwise相加\n",
    "\n",
    "![31](31.PNG)\n",
    "\n",
    "注意,它每一层都会输出一个结果\n",
    "\n",
    "这样, 它能输出多个不同尺度的feature map\n",
    "\n",
    "![33](33.PNG)\n",
    "\n",
    "其中3x3是为了消除aliasing effect\n",
    "\n",
    "把大的anchor对应到小的特征图上, 把小的对应到大的特征图上\n",
    "\n",
    "![35](35.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retina Net 2018\n",
    "\n",
    "[论文地址](https://arxiv.org/pdf/1708.02002.pdf)\n",
    "\n",
    "作者认为one stage精度不行, 不在于没做RPN, 而是因为Loss不行\n",
    "\n",
    "CEloss, 只是对正负样本, 不同类别物体做了分类\n",
    "\n",
    "没有考虑分类难易程度的不均衡, 正负样本分布的不均衡 \n",
    "\n",
    "某个样本多, 产生的Loss就多, 训练的模型就朝着那个样本的方向偏\n",
    "## Focal Loss\n",
    "\n",
    "产生Loss多的, 权重小\n",
    "\n",
    "交叉熵中P接近01的容易判断, 而P=0.5的就是难的样本\n",
    "\n",
    "$$Loss: \\;\\sum-\\alpha(1-P)^{\\alpha} \\log P$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD 2015\n",
    "\n",
    "加了anchor的多尺度预测\n",
    "\n",
    "anchor直接预测类别\n",
    "\n",
    "都是来自不同尺度特征图的\n",
    "\n",
    "anchor free的网络是一种趋势"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mAP mean average precision\n",
    "\n",
    "判断一个物体框对于否, 需要一个IoU阈值\n",
    "\n",
    "比如:\n",
    "\n",
    "超过0.7, 就是TP\n",
    "\n",
    "小于0.3 ,就是FN\n",
    "\n",
    "每个类别都有混淆矩阵, 不同的阈值对应了混淆矩阵里4个值\n",
    "\n",
    "当某一类别固定, 对不同的阈值画曲线, 叫PR curve\n",
    "\n",
    "Precision:你预测为真的有多少是真的真?\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "\n",
    "Recall: 对于所有真实为真的, 你预测对了多少?\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "## PR曲线 Precision - Recall Curve\n",
    "\n",
    "![50](50.PNG)\n",
    "\n",
    "\n",
    "通过不同的模型得到这么一条曲线, \n",
    "\n",
    "如何选点: 一般要均衡 precision和 Recall,  要看一些指标, 比如: \n",
    "$$ F1\\_score = \\frac{2}{\\frac{1}{Precision}+\\frac{1}{Recall}}$$\n",
    "\n",
    "面积auc应该越大越好\n",
    "\n",
    "不同的类别曲线不一样, 所有类别的曲线下的面积, 平均\n",
    "\n",
    "就是mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v3 代码\n",
    "\n",
    "[重写的版本: git地址](github.com/reigngt09/yolov3workflow)\n",
    "\n",
    "YOLO v3 跨平台用pytorch重写, 会变慢\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "v1的loss不明白\n",
    "\n",
    "v2的归一化, 那个anchors啥意思\n",
    "\n",
    "P2-P6啥意思"
   ]
  }
 ]
}