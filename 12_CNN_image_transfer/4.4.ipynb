{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以图生图\n",
    "- 图像分割\n",
    "- 风格转换\n",
    "- 其他"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像分割Image Segmentation\n",
    "\n",
    "> 分割, 分类, 检测是cv的3个基本问题\n",
    "\n",
    "## 三者比较:\n",
    "\n",
    "#### 分类: \n",
    "\n",
    "输入图片\n",
    "\n",
    "输出类别向量或标量\n",
    "\n",
    "3维或2维变成1维或0维\n",
    "\n",
    "可以看成语义提取\n",
    "\n",
    "#### 检测:\n",
    "位置回归, 类别分类\n",
    "\n",
    "输入图片\n",
    "\n",
    "输出位置向量和类别向量\n",
    "\n",
    "#### 分割:\n",
    "以图生图\n",
    "\n",
    "\n",
    "\n",
    "输入图, 输出还是图, 这个图要对原图的每一个像素的类别进行判别\n",
    "\n",
    "\n",
    "\n",
    "1. 每个像素都对应, 宽高大小不变, 每个channel都是一个类别, 每个像素只有0,1是还不是这种信息. 相当于多个2分类\n",
    "\n",
    "2. 每个像素都对应, 宽高大小不变, 但只有1个channel, 每个像素的数值可以不固定 \n",
    "\n",
    "**子领域:**\n",
    "- 语义分割semantic\n",
    "    - 树, \n",
    "    - 蓝天白云, 都算背景\n",
    "    - 多个人同一类\n",
    "- 实例分割instance\n",
    "    - 多个人不是同一类\n",
    "- 全景分割panoptic\n",
    "    - 结合前两个\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割的难点\n",
    "- 多尺度\n",
    "- 多姿态(多视角)\n",
    "- 物体之间遮挡\n",
    "- 光照\n",
    "    - 分割在医疗影响, 无人车, 航拍, 机器人方向应用很多\n",
    "- 边缘\n",
    "    - 比如人, 分割要描出轮廓\n",
    "    - 如果是仙人掌,就很难\n",
    "- 人工标注昂贵有噪声\n",
    "- 尺寸不变导致网络更需要显存,实时性难\n",
    "- 语义交互, 先验知识的利用\n",
    "    - 笔记本总是和桌子交互在一起\n",
    "    - 交通灯总是在路中间\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分割应用\n",
    "\n",
    "![1](1.PNG)\n",
    "\n",
    "航拍图, Label是人工标注, FCN最好\n",
    "\n",
    "![2](2.PNG)\n",
    "\n",
    "医疗\n",
    "\n",
    "![3](3.PNG)\n",
    "\n",
    "无人车"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四种网络\n",
    "- FCN全卷积网络\n",
    "- UNet/ENet\n",
    "- Mask/RCNN\n",
    "- Developments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN网络 2015\n",
    "\n",
    "[论文地址](https://people.eecs.berkeley.edu/%7Ejonlong/long_shelhamer_fcn.pdf)\n",
    "\n",
    "![4](4.PNG)\n",
    "\n",
    "1. 经过5次pooling, 长和高都是原来的1/32\n",
    "\n",
    "2. 第一种方案：然后做上采样(小图变大图)，直接变回原尺寸\n",
    "\n",
    "> 上采样的方式:\n",
    "- 插值\n",
    "- 转置卷积(同义词: 反卷积/分数步长卷积Fractional stride convolution)\n",
    "    - X是4x4的矩阵, 经过卷积变成一个2x2的Y\n",
    "    - 很可能经过了卷积: 3x3, stride=1,padding=0\n",
    "    - 那么可以写成 Y(4x1) = C(4x16) · X(16x1)\n",
    "    - 反过来X(16x1) = C^T(16x4) · Y(4x1)\n",
    "    - C^T未必是C^T\n",
    "    - 需要先在小图周围做很多padding0，再看看上采样的参数（步长，倍率）然后插值很多0\n",
    "\n",
    "3. (第二种方案)为了保留位置信息和语义信息，把不同的尺度进行融合，把 上次的pooling的结果 和 这次pooling结果的2x 做elementwise的相加。然后再上采样得到原图1/2大小\n",
    "\n",
    "4. 把多个pooling的结果转化成同一尺度再elementwise的相加， 然后做原图1/4的上采样\n",
    "\n",
    "\n",
    "### 特点：\n",
    "- 没有FC，没有向量，直接大图变小图，小图再变大图\n",
    "- 上采样需要学习细节， 用了转置卷积。转置卷积是可以学习的\n",
    "- 深层浅层的特征融合Shortcut between lower and deeper layers\n",
    "\n",
    "为什么pooling1和pooling2不融合呢？作者实践发现效果不够好\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unet 2015\n",
    "\n",
    "[论文地址](https://arxiv.org/pdf/1505.04597.pdf)\n",
    "\n",
    "![5](5.jpg)\n",
    "\n",
    "\n",
    "![6](6.PNG)\n",
    "\n",
    "白色和蓝色只是channel维度上连接在一起，不是elementwise相加\n",
    "\n",
    "\n",
    "声纳，声波，医疗用的多\n",
    "\n",
    "其实原图就是388x388x2，先padding到了572, 为什么？\n",
    "\n",
    "原因：医学领域每张图片 来之不易，图像边缘也有信息：\n",
    "\n",
    "Tile Strategy：\n",
    "\n",
    "padding填充图片边缘本身（镜像padding）\n",
    "\n",
    "\n",
    "为什么只在同尺度融合？也就是只在平行的地方融合？\n",
    "\n",
    "效果一般。\n",
    "\n",
    "（面试重点）\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unet很准，但是很慢，医疗可以，无人车就算了\n",
    "\n",
    "## 改进速度：E-Net\n",
    "[论文地址](https://arxiv.org/pdf/1606.02147.pdf)\n",
    "\n",
    "![7](7.PNG)\n",
    "\n",
    "卷积层数增加，特征图尺寸减小，但感受野增加，通道数增加，信息并不损失，所以大多数都是有大到小再由小到大\n",
    "\n",
    "为什么ENet中间为什么尺度不变：\n",
    "- 为了加速，通道数少，只有128\n",
    "- 再缩小尺寸对速度不明显\n",
    "- 为了增加感受野，用空洞卷积\n",
    "\n",
    "加速手段：\n",
    "- 通道数减少\n",
    "- 尺寸不变\n",
    "- 非对称卷积 \n",
    "\n",
    "此外借鉴了ResNet的BottleNeck模块，而且微调了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask-RCNN 2017\n",
    "\n",
    "[论文地址](https://arxiv.org/pdf/1703.06870.pdf)\n",
    "\n",
    "使用了FPN作为backbone\n",
    "\n",
    "精度高, 尤其是重叠时, 5fps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developments\n",
    "\n",
    "- FCN\n",
    "    - 深度学习领域(不算传统cv)比较早的\n",
    "- 转置卷积->插值的趋势\n",
    "- DeepLab: FCN和CRF(条件向量场)结合的\n",
    "- 空洞卷积是个趋势\n",
    "- BackBone不断改进, \n",
    "    - VGG,ResNet, EfficientNet,Repnet2020\n",
    "- 多尺度融合的趋势(金字塔)\n",
    "- 正负样本划分: \n",
    "    - ICNet(30FPS),级联, 每次选的正负样本不一样,\n",
    "- 针对标注困难: 半监督,非监督,自监督\n",
    "    - 自监督是只有数据没有label,但是前预设一些伪标签\n",
    "    - [论文](https://arxiv.org/pdf/1502.02734.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 风格转换 \n",
    "\n",
    "\n",
    "> 把一张艺术照风格变换到实际照片上\n",
    "\n",
    "## [2015论文](https://arxiv.org/pdf/1603.08155.pdf)观点:\n",
    "- 任意一张图片都可以表示为内容+风格\n",
    "- 层数越深, 语义信息多, 局部信息(位置,边缘,纹理)少, 反之亦然\n",
    "- 图A的内容Ac, 风格As, 图B的内容Bc, 风格Bs, 我们需要一张图X, 使得L(Xs-As)+L(Xc-Bc)最小\n",
    "\n",
    "### 过程:\n",
    "\n",
    "![8](8.PNG)\n",
    "\n",
    "1. 风格图经过Vgg16,长高缩小1/16,(去掉最后一次pooling)\n",
    "2. 每一层不同深度的特征图出来,转换成Gram矩阵, 最小的叫AL, 然后AL-1等等\n",
    "3. 内容图片也用Vgg16, 但是参数不训练, 用别人训练好的\n",
    "4. 一张噪声图,作为求解的初始值,也输入vgg16,得到特征图,每一层与风格图的特征图做加权Loss\n",
    "5. 求解图的特征图, 只有最第4层和内容图的第4层做逐像素点的L2 loss\n",
    "\n",
    "\n",
    "### 为什么内容只用一层的Loss,而风格每层都用?\n",
    "\n",
    "比如拍照, 位置偏移一点, 内容其实是不变的,但是这两张L2loss很大\n",
    "\n",
    "我们需要保持平移不变性, 对深层语义信息提取\n",
    "\n",
    "也就是内容是空间无关的\n",
    "\n",
    "\n",
    "\n",
    "### Gram矩阵\n",
    "\n",
    "什么是风格\n",
    "\n",
    "图片中某些纹理, 比如三个固定相对距离的蓝点总是重复出现\n",
    "\n",
    "Gram矩阵是对特征相关性的一种描述\n",
    "\n",
    "两种算法:\n",
    "\n",
    "1. HxWxC的特征图\n",
    "\n",
    "每个channel拿出来, 每个通道表示原图的一种响应\n",
    "\n",
    "协方差矩阵:CxC对称方阵\n",
    "\n",
    "每个i,j位置的元素都是第i个特征图和第j个特征图的 element相乘再相加 可以再除以WxHxC做一个归一化\n",
    "\n",
    "2. HxWxC的特征图\n",
    "\n",
    "每个2维特征图变成一维向量, 得到c行, 这个矩阵乘以它的转置, 和上面的得到的Gram矩阵一样的\n",
    "\n",
    "但是2015这个文章每次都要训练, 比较慢. 好处是不用训练集\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2016论文](https://cs.stanford.edu/people/jcjohns/papers/eccv16/JohnsonECCV16.pdf)\n",
    "\n",
    "- 把问题模块化\n",
    "- 使用时更快, 不用重复训练\n",
    "- Perceptual Loss 感知Loss\n",
    "- L1适合细节不适合颜色, L2相反\n",
    "\n",
    "\n",
    "## 结构&过程\n",
    "\n",
    "![9](9.PNG)\n",
    "\n",
    "\n",
    "Image Transform Net需要训练\n",
    "\n",
    "输出一个图\n",
    "\n",
    "再进入LossNet(不用训练), 分别计算风格Loss和内容Loss\n",
    "\n",
    "\n",
    "## 感知Loss\n",
    "\n",
    "![10](10.PNG)\n",
    "\n",
    "上采样时, 生成图片往往有棋盘格的奇怪纹理\n",
    "\n",
    "这是由于转置卷积本身稀疏导致的\n",
    "\n",
    "为了约束这种纹理, 加了一种Loss,限制梯度\n",
    "\n",
    "这里就是\n",
    "$$L_{TV}=\\sqrt{G_{x}^{2}+G_{y}^{2}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  特征模仿Feature Mimicking/模型蒸馏Model Distillation\n",
    "\n",
    "模型蒸馏和特征模仿有一定的类似\n",
    "\n",
    "为了提高速度:\n",
    "\n",
    "0. 模型的设计, shufflenet,mobilenet等\n",
    "1. 模型量化, 参数的类型压缩,\n",
    "2. 删除和剪枝, 小的权重丢弃, 有些神经元不需要\n",
    "3. 模型蒸馏\n",
    "\n",
    "\n",
    "### 模型蒸馏\n",
    "\n",
    "要把一个大模型变成小模型,\"蒸馏出知识\", 权重就是知识\n",
    "\n",
    "用蒸馏过后的知识指导小模型的学习\n",
    "\n",
    "用小模型替代大模型\n",
    "\n",
    "https://www.cs.toronto.edu/%7Ehinton/absps/distillation.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1412.6550.pdf\n",
    "\n",
    "http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf\n",
    "\n",
    "主要用在分类\n",
    "\n",
    "![11](11.PNG)\n",
    "\n",
    "\n",
    "\n",
    "a 就是正常的大模型进行分类的训练预测\n",
    "\n",
    "b 用大模型对要预测的图片生成更软的类别\n",
    "\n",
    "人工标注的时候,用小数(软),而不是01(硬), 知识更丰富\n",
    "\n",
    "$$ SoftMax : \\;\\;a_{i}=\\frac{e^{z_{i}}}{\\sum_{k=1}^{5} e^{z_{k}}}$$\n",
    "\n",
    "其实e的次幂可以都除以T,当T等于0, softmax很硬,当T = 无穷大, softmax很软\n",
    "\n",
    "c 把b得到的软标签保存下来, 当作浓缩的知识, 交给新的小模型训练\n",
    "\n",
    "小模型同时用软硬两种训练\n",
    "\n",
    "最终用单独用小模型预测\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他\n",
    "\n",
    "## 图像增强,变亮\n",
    "\n",
    "通道分离, 比如yuv\n",
    "\n",
    "模块化, 训练一个网络, 将暗图片变成亮图片, 需要两种数据\n",
    "\n",
    "高频低频分离\n",
    "\n",
    "## 去反光\n",
    "\n",
    "训练集拍摄有玻璃和没玻璃的\n",
    "\n",
    "## 去雾霾化\n",
    "\n",
    "## 超分辨,更清晰\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdeeplearningconda4eb25749ed314365ad1de507c177859b",
   "display_name": "Python 3.7.6 64-bit ('deeplearning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}